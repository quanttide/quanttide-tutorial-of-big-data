# 对intro章的补充
## 技术组内部会议内容
首先Hadoop他提出了一种专门用来处理大数据的整体的框架，包括一个调度，一个存储，一个计算。最重要的存储部分就是 HDFS（Hadoop 分布式文件系统），这种文件存储形式至今仍在使用。相比之下，主流的 NAS（网络附加存储）也可以作为独立的文件系统，许多本地硬件存储设备和云厂商提供的文件存储大多都基于 NAS 协议。但是NAS不太适合去处理大规模的数据流，当高并发处理大规模数据流程，就会炸。那么 HDFS，它就是从底层通过重写一个文件系统去解决这个问题的。所以它有一套专门的文件协议，以及对于它的一些底层。这些内容前面讲HDFS和 GFS 的时候才讲的内容。

HDFS是因为 NAS 这种文件系统不适合处理大数据。在上层增加了一个调度是为了调度海量的机器。MapReduce是为了在这样的机器上进行计算，然后跟这个文件系统结合起来。

MapReduce 以及它的调度程序下调度功能yarn。yarn封装了一个 master flavor的分布式结构。分布式调度从简单到复杂很多种，比如说最简单的结构就是 master flavor结构，master flavor 就是有一个节点是中心节点，其他是一个调度节点。这样的好处是结构很简单，坏处是master炸了就整个系统都炸了。在这个基础上有很多对于分布式系统的改进，比如所有的机器都可以做 master 也可以做 flavor，或者用几个master进行备份，用这种方法提高调度效率。
MapReduce是在这个基础之上又做了一个通用的框架，首先把这些任务给分发到每个flavor上。然后再想办法把这些flavor计算出来的结果拿过来加总，第一步就是 map 第二步是 reduce，那么这样就它就通过这套框架去解决了大数据调度的问题。

整个Hadoop的各个组件的底层有很多，对于硬件层面的协议，对于硬软件协议的优化，这些是让它能够好用的关键。但是Hadoop有明显的缺点：耦合性太好，无法进行比较弹性的扩容和缩容，比如有的项目计算量不大但存储量很大，那么假设硬件被限制在了这个规模，无法方便的去扩展。所以传统Hadoop框架它就像我们在用虚拟机一样，只能够固定一个规则去用它就很不方便。
因此，新技术的演化方向，就所谓的云原生，其中一条非常关键的思想就是存算分离。存算分离这个思想大家都知道，但是为什么只有到了10年之后才做起来的，因为存算分离依赖很强的网络速度，网络请求速度。我把HDFS 和 map reduce 拆开每一个HDFS增加一个调度，每个MapReduce增加一个调度组件，理论上来讲，就有了存储大规模数据的分布式存储和处理大规模数据的分布式计算。沿着这条思路，很多现代的东西就是这么做的，比如说云厂商就发明了很多基础设施，我们刚才提到的文件系统 NAS，还有对象存储。
对象存储，就是用 STP 请求去代替了文件协议。这样的一个好处，就是每一个 STP 请求，因为都是独立的，所以说它能够支持很高的并发上限，因为你的文件系统非常受制于那个文件系统的瓶颈。这样对象存储就作为一种比较现代的存储逐渐就代替了文件存储块存储，这些方式成为了现在各种大数据库的底层设施，比如click直接把s3作为底层。这个时候专用的HDFS，它依然有很多的作用，比如说你需要极高的效率的时候，HDFS 依然有用，但是绝大多数场景之下，对象存储可能会更好。

计算这条线的发展是因为MapReduce太慢了，有人就发明了Spark，这时候Spark还是在Hadoop的生态中的。后来大家发现Spark可以独立作为独立的路径和其它东西组合，就成为了一个相对比较独立的分布式计算。Spark的基本原理就是把所有的数据全部放到内存里面。这时候发现有了Spark有了对象存储，把这两个放在一起就有了新的东西，这就是数据湖的雏形。在这个基础上，加上元数据管理等，就变成数据湖了。

数据仓库是在Hadoop的基础上加上HBase,Hive这些，这就是BigTable的实现。重点是 Hive，Hive可以直接用 SQL 去查询。Hive是在 map reduce 的上面又搭了一个 SQL，把 SQL 转化成 mapreduce。但是这个框架的问题是太慢，MapReduce慢，在他的基础上搭出来的东西都慢。

那后来人们就想了，既然有数仓这种东西，也有这种调度方案。那为什么不把数仓的思想和这个结合起来，直接在底层去调度数据库专用的计算引擎就行。所以在这个思想之下，包括列式数据库这个思想被数据仓库广泛的吸收过之后，特别是 clickhouse 为代表，大家就开始说，那我们干脆就把各种大数据的调度的逻辑直接写到数据仓库里面，那就可以实现这个数据仓库的大规模的计算了。而且比较现代的数据仓库和事务型数据库普遍采用了块存储或对象存储的管理方式。一般分布式的可能对象存储用的会更多一点。因为它的结构，反而会更适合高并发。

上层的计算，一般都是 k8s 这种最多，也有可能是传统的虚拟机子群，都有可能出现。直接去运行一个 sql 计算引擎，直接用现在的一些调度工具，这样子的话，就可以有更高效的数据仓库了，加上数据仓库底层也有非常多吸收了Hadoop,HDFS,BigTable 的一些思想，所形成的一些比较现代的优化方法，就让现在的数据仓库比之前要快很多。所以被俄罗斯的搜索公司发明出来过之后，它就逐渐的非常的流行，大家就都在用它。

这个数据仓库还有一条线是调度，就是大家后来发明的 k8s ， k8s 之前首先是发明的容器，就是用以容器作为一个环境来去运行一个应用，然后又去为了调度容器发明了 k8s ，然后 k8s 的这套方案开源了之后，逐渐就代替了各个大厂自己自研的一些早期的方案，包括微信，他也把自己自研的方案就变成了 K8S 。腾讯云在上这个方面做的还是挺坚决的，几个大厂做的都比较坚决，那个阿里云其实做的最坚决，然后过于坚决了，就导致说他一出事故，阿里云出事故，所有的阿里产品都出事故。也充分反映了现在现代系统的脆弱性。k8s 这种方案，它基本上就成为了这些上层的底层，就是基本上主要用大规模调度计算的，除了自己本身有调度引擎之外，绝大多数比较现代的新开发的框架都会用 k8s，因为就是从调度的能力上来讲，无论是弹性扩容的水平，还是调度水平都没有比 K8S 做的更好的。

然后存储，计算，调度，这大数据三个框架，在大家吸收了Hadoop的思想之后，就形成了现在的数据湖，数据仓库，包括通用的云原生的基础设施。通用的云原生的基础设施，就不断的去作为数据湖和数据仓库的支撑，简单来讲就是说明线是Hadoop数据湖和数据仓库的研发，暗线是底层的硬件虚拟化程度逐渐提高，调度的能力提高实现了云原生化，那这个云原生就对数据仓库能够进行低成本的海量的扩缩容和数据这种形式提供了基础。

后来人们又发现数据仓库适合处理结构化数据，数据湖适合处理非结构化数据一个实际项目中有大量的结构化数据和非结构化数据，那我怎么把它们整合到一起？这时候就有两条路线，一条路线说把数据仓库作为数据湖的一个存储设施导入进去，这种方式会让我获得数据仓库的能力，但是它还不够快，因为它要转移可能还不够快。
后来人们就发明了另外一条路线就是ClickHouse，直接把数据湖的引擎和数据仓库引擎结合起来。首先用元数据管理平台去读我底层的数据，我不去预先定义好我数据表是什么。比如说把 SQL导入进来，我不去看这个 SQL是什么，就是元数据管理的思想，然后导入完后进来之后我知道了大部分的数据都可以用的，虽然说我没有直接去约束它，但是因为数据处理过程，我知道它是可靠的，那么我就能把这个元数据直接用起来。这就是ClickHouse。这样的话。我觉得这种相对比较灵活的前期处理应该前期处理方比较复杂，又能够到分析阶段有比较好的这种约束，又可以充分的去利用这个事。这就是ClickHouse。这条路线，现在也还在发展。因为这会涉及到效率，可靠性各种各样的问题，它还有管理上的问题。
