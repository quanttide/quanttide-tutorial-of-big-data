# 大数据技术的发展脉络
## Hadoop：现代大数据技术的起点 
&emsp;&emsp;现代大数据技术的发展始于2003年Google发布的三大奠基性论文。GFS分布式文件系统解决了海量数据存储问题，MapReduce建立了分布式计算范式，BigTable是一个列式数据库系统，为结构化数据存储提供了新思路。这三项技术构成了现代大数据技术的理论基础，但Google并未开源其实现。    
&emsp;&emsp;在雅虎等企业推动下，开源社区于2006年推出Hadoop生态系统——这是一个由Apache基金会维护的分布式计算框架，其核心设计包含两大模块：HDFS（分布式文件系统）负责数据存储，MapReduce（分布式计算模型）处理任务调度与并行计算 。具体实现中，HDFS继承GFS的核心思想实现海量文件存储，MapReduce完成计算逻辑的抽象封装，后来加入的HBase则对标BigTable提供列式存储能力。这标志着大数据技术从理论研究迈入工业化应用阶段，企业首次能够通过廉价x86服务器集群处理PB级数据。
## Hadoop 影响数据湖与数据仓库
&emsp;&emsp;Hadoop早期生态存在明显局限性：MapReduce的批处理模式导致计算延迟高达数小时，Hive查询响应常需分钟级，HDFS与计算节点的强耦合架构使得集群扩展困难。此时云计算开始兴起，AWS S3对象存储（2006年推出）凭借无限扩展性和存算分离特性，逐渐取代HDFS成为主流存储方案。2012年Spark的出现带来转折点，其内存计算模型将计算效率提升百倍，DAG执行引擎支持复杂任务编排，这直接冲击了传统MapReduce的地位。以Spark为代表的先进计算引擎不仅取代了MapReduce，还推动了架构革新——基于S3的存算分离架构催生出新一代数据湖（支持多模态原始数据存储与按需计算的分析范式），典型代表如Databricks公司。    
&emsp;&emsp;而数据仓库技术在此过程中经历了重大变革。传统数仓（如Teradata）受限于高昂的扩展成本和僵化的Schema设计，而Hadoop生态启发了新一代云数仓的演进方向。Snowflake（2012）首创存储计算分离架构，Redshift（2012）采用列式存储优化分析性能，ClickHouse（2016）则以向量化引擎实现单表查询的极致速度。这些技术创新使得数据分析延迟从小时级压缩到秒级，典型场景下ClickHouse的查询性能可达Hive的百倍以上。
## 数据湖与云数仓的融合趋势
&emsp;&emsp;数据湖与云数仓形成互补：前者支持非结构化数据灵活存取，后者专注结构化数据高效分析。  但两者各有局限——数据仓库难以处理日志/图片等非结构化数据，数据湖缺乏对结构化数据的强约束和优化能力。由此催生出湖仓一体（Lakehouse）架构：基于对象存储（如S3）实现低成本数据湖底座，通过Delta Lake/Iceberg元数据层添加Schema约束和ACID事务，同时兼容Spark（批处理）、Flink（流计算）、Presto（交互分析）多类引擎。电商平台可借此统一存储用户行为日志（非结构化）和订单表（结构化），在保证数据一致性的前提下，用Flink实时计算GMV，通过Presto亚秒级查询用户画像。   
